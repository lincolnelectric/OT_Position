{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yH27CHe0mv_7",
    "outputId": "61c7eea8-0088-49d9-f089-12531ff86e13"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z3FIPYrAZwbY"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOJK_uNaZwba"
   },
   "source": [
    "\n",
    "Transfer Learning for Computer Vision Tutorial\n",
    "==============================================\n",
    "\n",
    "These two major transfer learning scenarios look as follows:\n",
    "\n",
    "-  **Finetuning the convnet**: Instead of random initialization, we\n",
    "   initialize the network with a pretrained network, like the one that is\n",
    "   trained on imagenet 1000 dataset. Rest of the training looks as\n",
    "   usual.\n",
    "-  **ConvNet as fixed feature extractor**: Here, we will freeze the weights\n",
    "   for all of the network except that of the final fully connected\n",
    "   layer. This last fully connected layer is replaced with a new one\n",
    "   with random weights and only this layer is trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Wih7PFZmZwbc"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgOZkRB3Zwbc"
   },
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "We will use torchvision and torch.utils.data packages for loading the\n",
    "data.\n",
    "\n",
    "The problem we're going to solve today is to train a model to classify\n",
    "**ants** and **bees**. We have about 120 training images each for ants and bees.\n",
    "There are 75 validation images for each class. Usually, this is a very\n",
    "small dataset to generalize upon, if trained from scratch. Since we\n",
    "are using transfer learning, we should be able to generalize reasonably\n",
    "well.\n",
    "\n",
    "This dataset is a very small subset of imagenet.\n",
    "\n",
    ".. Note ::\n",
    "   Download the data from\n",
    "   `here <https://download.pytorch.org/tutorial/hymenoptera_data.zip>`_\n",
    "   and extract it to the current directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "_fGla5k3Zwbd",
    "outputId": "0228cd54-ab59-4bc4-f47a-a3b3d406bf00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168537 42177\n",
      "168537 42177\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "image_transforms  = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees = 45),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "dataset = 'E:\\gmd_data\\microsphere2_dataAugmented'\n",
    "train_directory = os.path.join(dataset, 'train')\n",
    "valid_directory = os.path.join(dataset, 'valid')\n",
    "\n",
    "batch_size = 32\n",
    "# num_classes = 173\n",
    "\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "\n",
    "train_data = DataLoader(data['train'], batch_size=batch_size, shuffle=True)\n",
    "valid_data = DataLoader(data['valid'], batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(train_data_size, valid_data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKqC2LN2Zwbd"
   },
   "source": [
    "迁移学习\n",
    "---------\n",
    "\n",
    "\n",
    "这里使用ResNet-50的预训练模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "o6u40PdzZwbe"
   },
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "fc_inputs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(64, 173),\n",
    "    nn.LogSoftmax(dim = 1)\n",
    "\n",
    "\n",
    ")\n",
    "resnet50 = resnet50.to('cuda:0')\n",
    "loss_func = nn.NLLLoss()\n",
    "# optimizer = optim.AdamW(resnet50.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4co9ExtXZwbe"
   },
   "source": [
    "Training the model\n",
    "------------------\n",
    "\n",
    "Now, let's write a general function to train a model. Here, we will\n",
    "illustrate:\n",
    "\n",
    "-  Scheduling the learning rate\n",
    "-  Saving the best model\n",
    "\n",
    "In the following, parameter ``scheduler`` is an LR scheduler object from\n",
    "``torch.optim.lr_scheduler``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uPoilgStZwbe"
   },
   "outputs": [],
   "source": [
    "def train_and_valid(model, loss_function, epochs=25):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "#         学习率递减\n",
    "        if epoch <= 10:\n",
    "            LR = 1e-4;\n",
    "        elif epoch <= 20:\n",
    "            LR = 1e-4*0.5;\n",
    "        elif epoch <= 30:\n",
    "            LR = 1e-4*0.5*0.5;\n",
    "        elif epoch <= 40:\n",
    "            LR = 1e-4*0.5*0.5*0.5;\n",
    "        else:\n",
    "            LR = 1e-4*0.5*0.5*0.5*0.5;\n",
    "        optimizer = optim.AdamW(resnet50.parameters(),lr=LR)\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_data):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            #因为这里梯度是累加的，所以每次记得清零\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for j, (inputs, labels) in enumerate(valid_data):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = loss_function(outputs, labels)\n",
    "\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "        avg_train_loss = train_loss/train_data_size\n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        avg_valid_loss = valid_loss/valid_data_size\n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "\n",
    "        if best_acc < avg_valid_acc:\n",
    "            best_acc = avg_valid_acc\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "        epoch_end = time.time()\n",
    "\n",
    "        print(\"Epoch: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation: Loss: {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(\n",
    "            epoch+1, avg_valid_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start\n",
    "        ))\n",
    "        print(\"Best Accuracy for validation : {:.4f} at epoch {:03d}\".format(best_acc, best_epoch))\n",
    "\n",
    "        torch.save(model, dataset+'/models/'+'model_'+str(epoch+1)+'.pt')\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9O0-Tn9PgT8u",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3000\n",
      "Epoch: 1/3000\n",
      "Epoch: 001, Training: Loss: 2.7878, Accuracy: 4.7230%, \n",
      "\t\tValidation: Loss: 2.7878, Accuracy: 15.0414%, Time: 8412.3150s\n",
      "Best Accuracy for validation : 0.1504 at epoch 001\n",
      "Epoch: 001, Training: Loss: 2.7878, Accuracy: 4.7230%, \n",
      "\t\tValidation: Loss: 2.7878, Accuracy: 15.0414%, Time: 8412.3150s\n",
      "Best Accuracy for validation : 0.1504 at epoch 001\n",
      "Epoch: 2/3000\n",
      "Epoch: 2/3000\n",
      "Epoch: 002, Training: Loss: 2.2598, Accuracy: 13.3917%, \n",
      "\t\tValidation: Loss: 2.2598, Accuracy: 18.2991%, Time: 8981.4649s\n",
      "Best Accuracy for validation : 0.1830 at epoch 002\n",
      "Epoch: 002, Training: Loss: 2.2598, Accuracy: 13.3917%, \n",
      "\t\tValidation: Loss: 2.2598, Accuracy: 18.2991%, Time: 8981.4649s\n",
      "Best Accuracy for validation : 0.1830 at epoch 002\n",
      "Epoch: 3/3000\n",
      "Epoch: 3/3000\n",
      "Epoch: 003, Training: Loss: 1.6855, Accuracy: 20.6530%, \n",
      "\t\tValidation: Loss: 1.6855, Accuracy: 30.5095%, Time: 8811.8746s\n",
      "Best Accuracy for validation : 0.3051 at epoch 003\n",
      "Epoch: 003, Training: Loss: 1.6855, Accuracy: 20.6530%, \n",
      "\t\tValidation: Loss: 1.6855, Accuracy: 30.5095%, Time: 8811.8746s\n",
      "Best Accuracy for validation : 0.3051 at epoch 003\n",
      "Epoch: 4/3000\n",
      "Epoch: 4/3000\n",
      "Epoch: 004, Training: Loss: 1.4812, Accuracy: 25.9350%, \n",
      "\t\tValidation: Loss: 1.4812, Accuracy: 38.7130%, Time: 8745.2444s\n",
      "Best Accuracy for validation : 0.3871 at epoch 004\n",
      "Epoch: 004, Training: Loss: 1.4812, Accuracy: 25.9350%, \n",
      "\t\tValidation: Loss: 1.4812, Accuracy: 38.7130%, Time: 8745.2444s\n",
      "Best Accuracy for validation : 0.3871 at epoch 004\n",
      "Epoch: 5/3000\n",
      "Epoch: 5/3000\n",
      "Epoch: 005, Training: Loss: 1.4132, Accuracy: 30.1898%, \n",
      "\t\tValidation: Loss: 1.4132, Accuracy: 39.3508%, Time: 8281.2216s\n",
      "Best Accuracy for validation : 0.3935 at epoch 005\n",
      "Epoch: 005, Training: Loss: 1.4132, Accuracy: 30.1898%, \n",
      "\t\tValidation: Loss: 1.4132, Accuracy: 39.3508%, Time: 8281.2216s\n",
      "Best Accuracy for validation : 0.3935 at epoch 005\n",
      "Epoch: 6/3000\n",
      "Epoch: 6/3000\n",
      "Epoch: 006, Training: Loss: 1.2154, Accuracy: 33.7178%, \n",
      "\t\tValidation: Loss: 1.2154, Accuracy: 52.4504%, Time: 8314.4973s\n",
      "Best Accuracy for validation : 0.5245 at epoch 006\n",
      "Epoch: 006, Training: Loss: 1.2154, Accuracy: 33.7178%, \n",
      "\t\tValidation: Loss: 1.2154, Accuracy: 52.4504%, Time: 8314.4973s\n",
      "Best Accuracy for validation : 0.5245 at epoch 006\n",
      "Epoch: 7/3000\n",
      "Epoch: 7/3000\n",
      "Epoch: 007, Training: Loss: 1.2791, Accuracy: 36.6543%, \n",
      "\t\tValidation: Loss: 1.2791, Accuracy: 38.4878%, Time: 8344.1881s\n",
      "Best Accuracy for validation : 0.5245 at epoch 006\n",
      "Epoch: 007, Training: Loss: 1.2791, Accuracy: 36.6543%, \n",
      "\t\tValidation: Loss: 1.2791, Accuracy: 38.4878%, Time: 8344.1881s\n",
      "Best Accuracy for validation : 0.5245 at epoch 006\n",
      "Epoch: 8/3000\n",
      "Epoch: 8/3000\n",
      "Epoch: 008, Training: Loss: 1.1361, Accuracy: 39.1309%, \n",
      "\t\tValidation: Loss: 1.1361, Accuracy: 54.9209%, Time: 8384.6401s\n",
      "Best Accuracy for validation : 0.5492 at epoch 008\n",
      "Epoch: 008, Training: Loss: 1.1361, Accuracy: 39.1309%, \n",
      "\t\tValidation: Loss: 1.1361, Accuracy: 54.9209%, Time: 8384.6401s\n",
      "Best Accuracy for validation : 0.5492 at epoch 008\n",
      "Epoch: 9/3000\n",
      "Epoch: 9/3000\n",
      "Epoch: 009, Training: Loss: 1.1118, Accuracy: 41.6407%, \n",
      "\t\tValidation: Loss: 1.1118, Accuracy: 55.3382%, Time: 8316.5371s\n",
      "Best Accuracy for validation : 0.5534 at epoch 009\n",
      "Epoch: 009, Training: Loss: 1.1118, Accuracy: 41.6407%, \n",
      "\t\tValidation: Loss: 1.1118, Accuracy: 55.3382%, Time: 8316.5371s\n",
      "Best Accuracy for validation : 0.5534 at epoch 009\n",
      "Epoch: 10/3000\n",
      "Epoch: 10/3000\n",
      "Epoch: 010, Training: Loss: 1.0734, Accuracy: 43.8438%, \n",
      "\t\tValidation: Loss: 1.0734, Accuracy: 56.2653%, Time: 8220.6728s\n",
      "Best Accuracy for validation : 0.5627 at epoch 010\n",
      "Epoch: 010, Training: Loss: 1.0734, Accuracy: 43.8438%, \n",
      "\t\tValidation: Loss: 1.0734, Accuracy: 56.2653%, Time: 8220.6728s\n",
      "Best Accuracy for validation : 0.5627 at epoch 010\n",
      "Epoch: 11/3000\n",
      "Epoch: 11/3000\n",
      "Epoch: 011, Training: Loss: 1.0144, Accuracy: 46.0196%, \n",
      "\t\tValidation: Loss: 1.0144, Accuracy: 57.8989%, Time: 8424.0412s\n",
      "Best Accuracy for validation : 0.5790 at epoch 011\n",
      "Epoch: 011, Training: Loss: 1.0144, Accuracy: 46.0196%, \n",
      "\t\tValidation: Loss: 1.0144, Accuracy: 57.8989%, Time: 8424.0412s\n",
      "Best Accuracy for validation : 0.5790 at epoch 011\n",
      "Epoch: 12/3000\n",
      "Epoch: 12/3000\n",
      "Epoch: 012, Training: Loss: 0.9149, Accuracy: 50.7325%, \n",
      "\t\tValidation: Loss: 0.9149, Accuracy: 66.9180%, Time: 8320.9056s\n",
      "Best Accuracy for validation : 0.6692 at epoch 012\n",
      "Epoch: 012, Training: Loss: 0.9149, Accuracy: 50.7325%, \n",
      "\t\tValidation: Loss: 0.9149, Accuracy: 66.9180%, Time: 8320.9056s\n",
      "Best Accuracy for validation : 0.6692 at epoch 012\n",
      "Epoch: 13/3000\n",
      "Epoch: 13/3000\n",
      "Epoch: 013, Training: Loss: 0.9367, Accuracy: 52.6128%, \n",
      "\t\tValidation: Loss: 0.9367, Accuracy: 65.5215%, Time: 8354.1486s\n",
      "Best Accuracy for validation : 0.6692 at epoch 012\n",
      "Epoch: 013, Training: Loss: 0.9367, Accuracy: 52.6128%, \n",
      "\t\tValidation: Loss: 0.9367, Accuracy: 65.5215%, Time: 8354.1486s\n",
      "Best Accuracy for validation : 0.6692 at epoch 012\n",
      "Epoch: 14/3000\n",
      "Epoch: 14/3000\n",
      "Epoch: 014, Training: Loss: 0.8909, Accuracy: 54.4041%, \n",
      "\t\tValidation: Loss: 0.8909, Accuracy: 68.8954%, Time: 8224.3794s\n",
      "Best Accuracy for validation : 0.6890 at epoch 014\n",
      "Epoch: 014, Training: Loss: 0.8909, Accuracy: 54.4041%, \n",
      "\t\tValidation: Loss: 0.8909, Accuracy: 68.8954%, Time: 8224.3794s\n",
      "Best Accuracy for validation : 0.6890 at epoch 014\n",
      "Epoch: 15/3000\n",
      "Epoch: 15/3000\n",
      "Epoch: 015, Training: Loss: 0.9422, Accuracy: 55.6566%, \n",
      "\t\tValidation: Loss: 0.9422, Accuracy: 63.6058%, Time: 8413.3526s\n",
      "Best Accuracy for validation : 0.6890 at epoch 014\n",
      "Epoch: 015, Training: Loss: 0.9422, Accuracy: 55.6566%, \n",
      "\t\tValidation: Loss: 0.9422, Accuracy: 63.6058%, Time: 8413.3526s\n",
      "Best Accuracy for validation : 0.6890 at epoch 014\n",
      "Epoch: 16/3000\n",
      "Epoch: 16/3000\n",
      "Epoch: 016, Training: Loss: 0.8671, Accuracy: 57.3298%, \n",
      "\t\tValidation: Loss: 0.8671, Accuracy: 66.9038%, Time: 8420.2203s\n",
      "Best Accuracy for validation : 0.6890 at epoch 014\n",
      "Epoch: 016, Training: Loss: 0.8671, Accuracy: 57.3298%, \n",
      "\t\tValidation: Loss: 0.8671, Accuracy: 66.9038%, Time: 8420.2203s\n",
      "Best Accuracy for validation : 0.6890 at epoch 014\n",
      "Epoch: 17/3000\n",
      "Epoch: 17/3000\n",
      "Epoch: 017, Training: Loss: 0.8788, Accuracy: 58.5634%, \n",
      "\t\tValidation: Loss: 0.8788, Accuracy: 67.2570%, Time: 8518.8632s\n",
      "Best Accuracy for validation : 0.6890 at epoch 014\n",
      "Epoch: 017, Training: Loss: 0.8788, Accuracy: 58.5634%, \n",
      "\t\tValidation: Loss: 0.8788, Accuracy: 67.2570%, Time: 8518.8632s\n",
      "Best Accuracy for validation : 0.6890 at epoch 014\n",
      "Epoch: 18/3000\n",
      "Epoch: 18/3000\n",
      "Epoch: 018, Training: Loss: 0.9320, Accuracy: 60.0521%, \n",
      "\t\tValidation: Loss: 0.9320, Accuracy: 65.8297%, Time: 8307.3785s\n",
      "Best Accuracy for validation : 0.6890 at epoch 014\n",
      "Epoch: 018, Training: Loss: 0.9320, Accuracy: 60.0521%, \n",
      "\t\tValidation: Loss: 0.9320, Accuracy: 65.8297%, Time: 8307.3785s\n",
      "Best Accuracy for validation : 0.6890 at epoch 014\n",
      "Epoch: 19/3000\n",
      "Epoch: 19/3000\n",
      "Epoch: 019, Training: Loss: 0.7999, Accuracy: 61.4684%, \n",
      "\t\tValidation: Loss: 0.7999, Accuracy: 74.1257%, Time: 8234.7468s\n",
      "Best Accuracy for validation : 0.7413 at epoch 019\n",
      "Epoch: 019, Training: Loss: 0.7999, Accuracy: 61.4684%, \n",
      "\t\tValidation: Loss: 0.7999, Accuracy: 74.1257%, Time: 8234.7468s\n",
      "Best Accuracy for validation : 0.7413 at epoch 019\n",
      "Epoch: 20/3000\n",
      "Epoch: 20/3000\n",
      "Epoch: 020, Training: Loss: 0.9810, Accuracy: 63.0366%, \n",
      "\t\tValidation: Loss: 0.9810, Accuracy: 65.1089%, Time: 8319.6256s\n",
      "Best Accuracy for validation : 0.7413 at epoch 019\n",
      "Epoch: 020, Training: Loss: 0.9810, Accuracy: 63.0366%, \n",
      "\t\tValidation: Loss: 0.9810, Accuracy: 65.1089%, Time: 8319.6256s\n",
      "Best Accuracy for validation : 0.7413 at epoch 019\n",
      "Epoch: 21/3000\n",
      "Epoch: 21/3000\n",
      "Epoch: 021, Training: Loss: 0.8171, Accuracy: 64.6974%, \n",
      "\t\tValidation: Loss: 0.8171, Accuracy: 70.4483%, Time: 8010.4017s\n",
      "Best Accuracy for validation : 0.7413 at epoch 019\n",
      "Epoch: 021, Training: Loss: 0.8171, Accuracy: 64.6974%, \n",
      "\t\tValidation: Loss: 0.8171, Accuracy: 70.4483%, Time: 8010.4017s\n",
      "Best Accuracy for validation : 0.7413 at epoch 019\n",
      "Epoch: 22/3000\n",
      "Epoch: 22/3000\n",
      "Epoch: 022, Training: Loss: 0.7793, Accuracy: 67.8444%, \n",
      "\t\tValidation: Loss: 0.7793, Accuracy: 74.3320%, Time: 8313.0873s\n",
      "Best Accuracy for validation : 0.7433 at epoch 022\n",
      "Epoch: 022, Training: Loss: 0.7793, Accuracy: 67.8444%, \n",
      "\t\tValidation: Loss: 0.7793, Accuracy: 74.3320%, Time: 8313.0873s\n",
      "Best Accuracy for validation : 0.7433 at epoch 022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/3000\n",
      "Epoch: 23/3000\n",
      "Epoch: 023, Training: Loss: 0.8611, Accuracy: 69.0596%, \n",
      "\t\tValidation: Loss: 0.8611, Accuracy: 70.8965%, Time: 8408.0875s\n",
      "Best Accuracy for validation : 0.7433 at epoch 022\n",
      "Epoch: 023, Training: Loss: 0.8611, Accuracy: 69.0596%, \n",
      "\t\tValidation: Loss: 0.8611, Accuracy: 70.8965%, Time: 8408.0875s\n",
      "Best Accuracy for validation : 0.7433 at epoch 022\n",
      "Epoch: 24/3000\n",
      "Epoch: 24/3000\n",
      "Epoch: 024, Training: Loss: 0.8013, Accuracy: 70.2611%, \n",
      "\t\tValidation: Loss: 0.8013, Accuracy: 74.0901%, Time: 8365.3434s\n",
      "Best Accuracy for validation : 0.7433 at epoch 022\n",
      "Epoch: 024, Training: Loss: 0.8013, Accuracy: 70.2611%, \n",
      "\t\tValidation: Loss: 0.8013, Accuracy: 74.0901%, Time: 8365.3434s\n",
      "Best Accuracy for validation : 0.7433 at epoch 022\n",
      "Epoch: 25/3000\n",
      "Epoch: 25/3000\n",
      "Epoch: 025, Training: Loss: 0.7899, Accuracy: 71.2045%, \n",
      "\t\tValidation: Loss: 0.7899, Accuracy: 73.2058%, Time: 8423.8834s\n",
      "Best Accuracy for validation : 0.7433 at epoch 022\n",
      "Epoch: 025, Training: Loss: 0.7899, Accuracy: 71.2045%, \n",
      "\t\tValidation: Loss: 0.7899, Accuracy: 73.2058%, Time: 8423.8834s\n",
      "Best Accuracy for validation : 0.7433 at epoch 022\n",
      "Epoch: 26/3000\n",
      "Epoch: 26/3000\n",
      "Epoch: 026, Training: Loss: 0.7543, Accuracy: 72.1841%, \n",
      "\t\tValidation: Loss: 0.7543, Accuracy: 77.2056%, Time: 8404.9979s\n",
      "Best Accuracy for validation : 0.7721 at epoch 026\n",
      "Epoch: 026, Training: Loss: 0.7543, Accuracy: 72.1841%, \n",
      "\t\tValidation: Loss: 0.7543, Accuracy: 77.2056%, Time: 8404.9979s\n",
      "Best Accuracy for validation : 0.7721 at epoch 026\n",
      "Epoch: 27/3000\n",
      "Epoch: 27/3000\n",
      "Epoch: 027, Training: Loss: 0.7528, Accuracy: 72.9377%, \n",
      "\t\tValidation: Loss: 0.7528, Accuracy: 76.2193%, Time: 8352.7937s\n",
      "Best Accuracy for validation : 0.7721 at epoch 026\n",
      "Epoch: 027, Training: Loss: 0.7528, Accuracy: 72.9377%, \n",
      "\t\tValidation: Loss: 0.7528, Accuracy: 76.2193%, Time: 8352.7937s\n",
      "Best Accuracy for validation : 0.7721 at epoch 026\n",
      "Epoch: 28/3000\n",
      "Epoch: 28/3000\n",
      "Epoch: 028, Training: Loss: 0.8207, Accuracy: 74.1760%, \n",
      "\t\tValidation: Loss: 0.8207, Accuracy: 74.9176%, Time: 7747.7625s\n",
      "Best Accuracy for validation : 0.7721 at epoch 026\n",
      "Epoch: 028, Training: Loss: 0.8207, Accuracy: 74.1760%, \n",
      "\t\tValidation: Loss: 0.8207, Accuracy: 74.9176%, Time: 7747.7625s\n",
      "Best Accuracy for validation : 0.7721 at epoch 026\n",
      "Epoch: 29/3000\n",
      "Epoch: 29/3000\n",
      "Epoch: 029, Training: Loss: 0.7930, Accuracy: 74.9497%, \n",
      "\t\tValidation: Loss: 0.7930, Accuracy: 73.8673%, Time: 8316.0652s\n",
      "Best Accuracy for validation : 0.7721 at epoch 026\n",
      "Epoch: 029, Training: Loss: 0.7930, Accuracy: 74.9497%, \n",
      "\t\tValidation: Loss: 0.7930, Accuracy: 73.8673%, Time: 8316.0652s\n",
      "Best Accuracy for validation : 0.7721 at epoch 026\n",
      "Epoch: 30/3000\n",
      "Epoch: 30/3000\n",
      "Epoch: 030, Training: Loss: 0.7693, Accuracy: 75.8023%, \n",
      "\t\tValidation: Loss: 0.7693, Accuracy: 77.4948%, Time: 7185.3099s\n",
      "Best Accuracy for validation : 0.7749 at epoch 030\n",
      "Epoch: 030, Training: Loss: 0.7693, Accuracy: 75.8023%, \n",
      "\t\tValidation: Loss: 0.7693, Accuracy: 77.4948%, Time: 7185.3099s\n",
      "Best Accuracy for validation : 0.7749 at epoch 030\n",
      "Epoch: 31/3000\n",
      "Epoch: 31/3000\n",
      "Epoch: 031, Training: Loss: 0.7836, Accuracy: 76.7647%, \n",
      "\t\tValidation: Loss: 0.7836, Accuracy: 73.7274%, Time: 7208.2856s\n",
      "Best Accuracy for validation : 0.7749 at epoch 030\n",
      "Epoch: 031, Training: Loss: 0.7836, Accuracy: 76.7647%, \n",
      "\t\tValidation: Loss: 0.7836, Accuracy: 73.7274%, Time: 7208.2856s\n",
      "Best Accuracy for validation : 0.7749 at epoch 030\n",
      "Epoch: 32/3000\n",
      "Epoch: 32/3000\n",
      "Epoch: 032, Training: Loss: 0.6982, Accuracy: 78.4605%, \n",
      "\t\tValidation: Loss: 0.6982, Accuracy: 78.0473%, Time: 7740.8255s\n",
      "Best Accuracy for validation : 0.7805 at epoch 032\n",
      "Epoch: 032, Training: Loss: 0.6982, Accuracy: 78.4605%, \n",
      "\t\tValidation: Loss: 0.6982, Accuracy: 78.0473%, Time: 7740.8255s\n",
      "Best Accuracy for validation : 0.7805 at epoch 032\n",
      "Epoch: 33/3000\n",
      "Epoch: 33/3000\n",
      "Epoch: 033, Training: Loss: 0.7224, Accuracy: 79.1494%, \n",
      "\t\tValidation: Loss: 0.7224, Accuracy: 79.3347%, Time: 8396.1221s\n",
      "Best Accuracy for validation : 0.7933 at epoch 033\n",
      "Epoch: 033, Training: Loss: 0.7224, Accuracy: 79.1494%, \n",
      "\t\tValidation: Loss: 0.7224, Accuracy: 79.3347%, Time: 8396.1221s\n",
      "Best Accuracy for validation : 0.7933 at epoch 033\n",
      "Epoch: 34/3000\n",
      "Epoch: 34/3000\n",
      "Epoch: 034, Training: Loss: 0.7491, Accuracy: 79.7142%, \n",
      "\t\tValidation: Loss: 0.7491, Accuracy: 76.9709%, Time: 8522.5748s\n",
      "Best Accuracy for validation : 0.7933 at epoch 033\n",
      "Epoch: 034, Training: Loss: 0.7491, Accuracy: 79.7142%, \n",
      "\t\tValidation: Loss: 0.7491, Accuracy: 76.9709%, Time: 8522.5748s\n",
      "Best Accuracy for validation : 0.7933 at epoch 033\n",
      "Epoch: 35/3000\n",
      "Epoch: 35/3000\n",
      "Epoch: 035, Training: Loss: 0.7467, Accuracy: 80.2945%, \n",
      "\t\tValidation: Loss: 0.7467, Accuracy: 75.0196%, Time: 8487.4049s\n",
      "Best Accuracy for validation : 0.7933 at epoch 033\n",
      "Epoch: 035, Training: Loss: 0.7467, Accuracy: 80.2945%, \n",
      "\t\tValidation: Loss: 0.7467, Accuracy: 75.0196%, Time: 8487.4049s\n",
      "Best Accuracy for validation : 0.7933 at epoch 033\n",
      "Epoch: 36/3000\n",
      "Epoch: 36/3000\n",
      "Epoch: 036, Training: Loss: 0.6818, Accuracy: 80.6333%, \n",
      "\t\tValidation: Loss: 0.6818, Accuracy: 78.0828%, Time: 7266.3552s\n",
      "Best Accuracy for validation : 0.7933 at epoch 033\n",
      "Epoch: 036, Training: Loss: 0.6818, Accuracy: 80.6333%, \n",
      "\t\tValidation: Loss: 0.6818, Accuracy: 78.0828%, Time: 7266.3552s\n",
      "Best Accuracy for validation : 0.7933 at epoch 033\n",
      "Epoch: 37/3000\n",
      "Epoch: 37/3000\n",
      "Epoch: 037, Training: Loss: 0.6863, Accuracy: 80.9496%, \n",
      "\t\tValidation: Loss: 0.6863, Accuracy: 77.8647%, Time: 7297.9431s\n",
      "Best Accuracy for validation : 0.7933 at epoch 033\n",
      "Epoch: 037, Training: Loss: 0.6863, Accuracy: 80.9496%, \n",
      "\t\tValidation: Loss: 0.6863, Accuracy: 77.8647%, Time: 7297.9431s\n",
      "Best Accuracy for validation : 0.7933 at epoch 033\n",
      "Epoch: 38/3000\n",
      "Epoch: 38/3000\n",
      "Epoch: 038, Training: Loss: 0.6523, Accuracy: 81.5394%, \n",
      "\t\tValidation: Loss: 0.6523, Accuracy: 81.3216%, Time: 8380.9847s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 038, Training: Loss: 0.6523, Accuracy: 81.5394%, \n",
      "\t\tValidation: Loss: 0.6523, Accuracy: 81.3216%, Time: 8380.9847s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 39/3000\n",
      "Epoch: 39/3000\n",
      "Epoch: 039, Training: Loss: 0.6905, Accuracy: 81.8734%, \n",
      "\t\tValidation: Loss: 0.6905, Accuracy: 78.8344%, Time: 7177.0423s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 039, Training: Loss: 0.6905, Accuracy: 81.8734%, \n",
      "\t\tValidation: Loss: 0.6905, Accuracy: 78.8344%, Time: 7177.0423s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 40/3000\n",
      "Epoch: 40/3000\n",
      "Epoch: 040, Training: Loss: 0.6800, Accuracy: 82.3671%, \n",
      "\t\tValidation: Loss: 0.6800, Accuracy: 77.6584%, Time: 7165.4367s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 040, Training: Loss: 0.6800, Accuracy: 82.3671%, \n",
      "\t\tValidation: Loss: 0.6800, Accuracy: 77.6584%, Time: 7165.4367s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 41/3000\n",
      "Epoch: 41/3000\n",
      "Epoch: 041, Training: Loss: 0.6992, Accuracy: 82.5148%, \n",
      "\t\tValidation: Loss: 0.6992, Accuracy: 78.4409%, Time: 7180.0553s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 041, Training: Loss: 0.6992, Accuracy: 82.5148%, \n",
      "\t\tValidation: Loss: 0.6992, Accuracy: 78.4409%, Time: 7180.0553s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 42/3000\n",
      "Epoch: 42/3000\n",
      "Epoch: 042, Training: Loss: 0.7085, Accuracy: 83.4446%, \n",
      "\t\tValidation: Loss: 0.7085, Accuracy: 76.9424%, Time: 7202.8630s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 042, Training: Loss: 0.7085, Accuracy: 83.4446%, \n",
      "\t\tValidation: Loss: 0.7085, Accuracy: 76.9424%, Time: 7202.8630s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 43/3000\n",
      "Epoch: 43/3000\n",
      "Epoch: 043, Training: Loss: 0.6958, Accuracy: 83.9679%, \n",
      "\t\tValidation: Loss: 0.6958, Accuracy: 78.3436%, Time: 7203.8156s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 043, Training: Loss: 0.6958, Accuracy: 83.9679%, \n",
      "\t\tValidation: Loss: 0.6958, Accuracy: 78.3436%, Time: 7203.8156s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 44/3000\n",
      "Epoch: 44/3000\n",
      "Epoch: 044, Training: Loss: 0.6769, Accuracy: 84.0765%, \n",
      "\t\tValidation: Loss: 0.6769, Accuracy: 79.5647%, Time: 8085.1803s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 044, Training: Loss: 0.6769, Accuracy: 84.0765%, \n",
      "\t\tValidation: Loss: 0.6769, Accuracy: 79.5647%, Time: 8085.1803s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/3000\n",
      "Epoch: 45/3000\n",
      "Epoch: 045, Training: Loss: 0.7106, Accuracy: 84.2278%, \n",
      "\t\tValidation: Loss: 0.7106, Accuracy: 77.7556%, Time: 9233.5630s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 045, Training: Loss: 0.7106, Accuracy: 84.2278%, \n",
      "\t\tValidation: Loss: 0.7106, Accuracy: 77.7556%, Time: 9233.5630s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 46/3000\n",
      "Epoch: 46/3000\n",
      "Epoch: 046, Training: Loss: 0.6661, Accuracy: 84.3643%, \n",
      "\t\tValidation: Loss: 0.6661, Accuracy: 80.0507%, Time: 9920.7980s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 046, Training: Loss: 0.6661, Accuracy: 84.3643%, \n",
      "\t\tValidation: Loss: 0.6661, Accuracy: 80.0507%, Time: 9920.7980s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 47/3000\n",
      "Epoch: 47/3000\n",
      "Epoch: 047, Training: Loss: 0.6815, Accuracy: 84.6152%, \n",
      "\t\tValidation: Loss: 0.6815, Accuracy: 78.2701%, Time: 12759.4504s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 047, Training: Loss: 0.6815, Accuracy: 84.6152%, \n",
      "\t\tValidation: Loss: 0.6815, Accuracy: 78.2701%, Time: 12759.4504s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 48/3000\n",
      "Epoch: 48/3000\n",
      "Epoch: 048, Training: Loss: 0.6873, Accuracy: 84.7434%, \n",
      "\t\tValidation: Loss: 0.6873, Accuracy: 78.5570%, Time: 15494.5561s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 048, Training: Loss: 0.6873, Accuracy: 84.7434%, \n",
      "\t\tValidation: Loss: 0.6873, Accuracy: 78.5570%, Time: 15494.5561s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 49/3000\n",
      "Epoch: 49/3000\n",
      "Epoch: 049, Training: Loss: 0.7007, Accuracy: 85.1617%, \n",
      "\t\tValidation: Loss: 0.7007, Accuracy: 77.6015%, Time: 13535.1470s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 049, Training: Loss: 0.7007, Accuracy: 85.1617%, \n",
      "\t\tValidation: Loss: 0.7007, Accuracy: 77.6015%, Time: 13535.1470s\n",
      "Best Accuracy for validation : 0.8132 at epoch 038\n",
      "Epoch: 50/3000\n",
      "Epoch: 50/3000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NANOLA~1\\AppData\\Local\\Temp/ipykernel_28536/2181074094.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrained_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'models/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_history.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\NANOLA~1\\AppData\\Local\\Temp/ipykernel_28536/1225346874.py\u001b[0m in \u001b[0;36mtrain_and_valid\u001b[1;34m(model, loss_function, epochs)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacondagmd\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacondagmd\\envs\\d2l\\lib\\site-packages\\torch\\autograd\\profiler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, args)\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;31m# Stores underlying RecordFunction as a tensor. TODO: move to custom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;31m# class (https://github.com/pytorch/pytorch/issues/35026).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NANOLA~1\\AppData\\Local\\Temp/ipykernel_28536/2181074094.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrained_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'models/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_history.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\NANOLA~1\\AppData\\Local\\Temp/ipykernel_28536/1225346874.py\u001b[0m in \u001b[0;36mtrain_and_valid\u001b[1;34m(model, loss_function, epochs)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacondagmd\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacondagmd\\envs\\d2l\\lib\\site-packages\\torch\\autograd\\profiler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, args)\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;31m# Stores underlying RecordFunction as a tensor. TODO: move to custom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;31m# class (https://github.com/pytorch/pytorch/issues/35026).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 3000\n",
    "trained_model, history = train_and_valid(resnet50, loss_func, num_epochs)\n",
    "torch.save(history, 'models/'+dataset+'_history.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.array(history)\n",
    "plt.plot(history[:, 0:2])\n",
    "plt.legend(['Tr Loss', 'Val Loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(dataset+'_loss_curve.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history[:, 2:4])\n",
    "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(dataset+'_accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset+'\\models\\\\'+'model_'+str(1)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( dataset+'/models/'+'model_'+str(1)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "“transfer_learning_tutorial.ipynb”的副本",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
