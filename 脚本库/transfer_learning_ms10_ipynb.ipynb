{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yH27CHe0mv_7",
    "outputId": "61c7eea8-0088-49d9-f089-12531ff86e13"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Z3FIPYrAZwbY"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOJK_uNaZwba"
   },
   "source": [
    "\n",
    "Transfer Learning for Computer Vision Tutorial\n",
    "==============================================\n",
    "\n",
    "These two major transfer learning scenarios look as follows:\n",
    "\n",
    "-  **Finetuning the convnet**: Instead of random initialization, we\n",
    "   initialize the network with a pretrained network, like the one that is\n",
    "   trained on imagenet 1000 dataset. Rest of the training looks as\n",
    "   usual.\n",
    "-  **ConvNet as fixed feature extractor**: Here, we will freeze the weights\n",
    "   for all of the network except that of the final fully connected\n",
    "   layer. This last fully connected layer is replaced with a new one\n",
    "   with random weights and only this layer is trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Wih7PFZmZwbc"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgOZkRB3Zwbc"
   },
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "We will use torchvision and torch.utils.data packages for loading the\n",
    "data.\n",
    "\n",
    "The problem we're going to solve today is to train a model to classify\n",
    "**ants** and **bees**. We have about 120 training images each for ants and bees.\n",
    "There are 75 validation images for each class. Usually, this is a very\n",
    "small dataset to generalize upon, if trained from scratch. Since we\n",
    "are using transfer learning, we should be able to generalize reasonably\n",
    "well.\n",
    "\n",
    "This dataset is a very small subset of imagenet.\n",
    "\n",
    ".. Note ::\n",
    "   Download the data from\n",
    "   `here <https://download.pytorch.org/tutorial/hymenoptera_data.zip>`_\n",
    "   and extract it to the current directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "_fGla5k3Zwbd",
    "outputId": "0228cd54-ab59-4bc4-f47a-a3b3d406bf00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038 346\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "image_transforms  = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "dataset = 'microsphere2'\n",
    "train_directory = os.path.join(dataset, 'train')\n",
    "valid_directory = os.path.join(dataset, 'valid')\n",
    "\n",
    "batch_size = 16\n",
    "num_classes = 173\n",
    "\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "\n",
    "train_data = DataLoader(data['train'], batch_size=batch_size, shuffle=True)\n",
    "valid_data = DataLoader(data['valid'], batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(train_data_size, valid_data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKqC2LN2Zwbd"
   },
   "source": [
    "迁移学习\n",
    "---------\n",
    "\n",
    "\n",
    "这里使用ResNet-50的预训练模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "o6u40PdzZwbe"
   },
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "fc_inputs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256,  173),\n",
    "    nn.LogSoftmax(dim = 1)\n",
    "\n",
    "\n",
    ")\n",
    "resnet50 = resnet50.to('cuda:0')\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.AdamW(resnet50.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4co9ExtXZwbe"
   },
   "source": [
    "Training the model\n",
    "------------------\n",
    "\n",
    "Now, let's write a general function to train a model. Here, we will\n",
    "illustrate:\n",
    "\n",
    "-  Scheduling the learning rate\n",
    "-  Saving the best model\n",
    "\n",
    "In the following, parameter ``scheduler`` is an LR scheduler object from\n",
    "``torch.optim.lr_scheduler``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uPoilgStZwbe"
   },
   "outputs": [],
   "source": [
    "def train_and_valid(model, loss_function, optimizer, epochs=25):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_data):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            #因为这里梯度是累加的，所以每次记得清零\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for j, (inputs, labels) in enumerate(valid_data):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = loss_function(outputs, labels)\n",
    "\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "        avg_train_loss = train_loss/train_data_size\n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        avg_valid_loss = valid_loss/valid_data_size\n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "\n",
    "        if best_acc < avg_valid_acc:\n",
    "            best_acc = avg_valid_acc\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "        epoch_end = time.time()\n",
    "\n",
    "        print(\"Epoch: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation: Loss: {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(\n",
    "            epoch+1, avg_valid_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start\n",
    "        ))\n",
    "        print(\"Best Accuracy for validation : {:.4f} at epoch {:03d}\".format(best_acc, best_epoch))\n",
    "        dataset1 = 'E:\\gmd_data\\microsphere2_dataAugmented'\n",
    "        torch.save(model, dataset1+'/models/'+'model_'+str(epoch+1)+'.pt')\n",
    "#         torch.save(model, 'models/'+dataset+'_model_'+str(epoch+1)+'.pt')\n",
    "        if epoch + 1 - 100 >  best_epoch:\n",
    "            break\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9O0-Tn9PgT8u",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3000\n",
      "Epoch: 001, Training: Loss: 5.1540, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1540, Accuracy: 0.5780%, Time: 107.1861s\n",
      "Best Accuracy for validation : 0.0058 at epoch 001\n",
      "Epoch: 2/3000\n",
      "Epoch: 002, Training: Loss: 5.1539, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1539, Accuracy: 0.5780%, Time: 40.0172s\n",
      "Best Accuracy for validation : 0.0058 at epoch 002\n",
      "Epoch: 3/3000\n",
      "Epoch: 003, Training: Loss: 5.1525, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1525, Accuracy: 0.8671%, Time: 39.0196s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 4/3000\n",
      "Epoch: 004, Training: Loss: 5.1539, Accuracy: 0.6744%, \n",
      "\t\tValidation: Loss: 5.1539, Accuracy: 0.5780%, Time: 37.3196s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 5/3000\n",
      "Epoch: 005, Training: Loss: 5.1539, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1539, Accuracy: 0.5780%, Time: 38.7533s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 6/3000\n",
      "Epoch: 006, Training: Loss: 5.1538, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1538, Accuracy: 0.5780%, Time: 38.7922s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 7/3000\n",
      "Epoch: 007, Training: Loss: 5.1538, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1538, Accuracy: 0.5780%, Time: 37.4913s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 8/3000\n",
      "Epoch: 008, Training: Loss: 5.1538, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1538, Accuracy: 0.5780%, Time: 36.6498s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 9/3000\n",
      "Epoch: 009, Training: Loss: 5.1538, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1538, Accuracy: 0.5780%, Time: 36.8521s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 10/3000\n",
      "Epoch: 010, Training: Loss: 5.1537, Accuracy: 0.4817%, \n",
      "\t\tValidation: Loss: 5.1537, Accuracy: 0.5780%, Time: 38.6690s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 11/3000\n",
      "Epoch: 011, Training: Loss: 5.1537, Accuracy: 0.4817%, \n",
      "\t\tValidation: Loss: 5.1537, Accuracy: 0.5780%, Time: 39.1402s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 12/3000\n",
      "Epoch: 012, Training: Loss: 5.1537, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1537, Accuracy: 0.5780%, Time: 38.6039s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 13/3000\n",
      "Epoch: 013, Training: Loss: 5.1537, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1537, Accuracy: 0.5780%, Time: 38.5605s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 14/3000\n",
      "Epoch: 014, Training: Loss: 5.1537, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1537, Accuracy: 0.5780%, Time: 38.5927s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 15/3000\n",
      "Epoch: 015, Training: Loss: 5.1537, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1537, Accuracy: 0.5780%, Time: 38.4692s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 16/3000\n",
      "Epoch: 016, Training: Loss: 5.1536, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1536, Accuracy: 0.5780%, Time: 33.1706s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 17/3000\n",
      "Epoch: 017, Training: Loss: 5.1536, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1536, Accuracy: 0.5780%, Time: 36.7482s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 18/3000\n",
      "Epoch: 018, Training: Loss: 5.1536, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1536, Accuracy: 0.5780%, Time: 38.2730s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 19/3000\n",
      "Epoch: 019, Training: Loss: 5.1536, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1536, Accuracy: 0.5780%, Time: 29.3052s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 20/3000\n",
      "Epoch: 020, Training: Loss: 5.1536, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1536, Accuracy: 0.5780%, Time: 30.9587s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 21/3000\n",
      "Epoch: 021, Training: Loss: 5.1536, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1536, Accuracy: 0.5780%, Time: 32.8968s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 22/3000\n",
      "Epoch: 022, Training: Loss: 5.1536, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1536, Accuracy: 0.5780%, Time: 38.5358s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 23/3000\n",
      "Epoch: 023, Training: Loss: 5.1536, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1536, Accuracy: 0.5780%, Time: 38.4629s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 24/3000\n",
      "Epoch: 024, Training: Loss: 5.1535, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 34.7526s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 25/3000\n",
      "Epoch: 025, Training: Loss: 5.1535, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 36.3123s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 26/3000\n",
      "Epoch: 026, Training: Loss: 5.1535, Accuracy: 0.4817%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 33.3248s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 27/3000\n",
      "Epoch: 027, Training: Loss: 5.1535, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 38.1759s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 28/3000\n",
      "Epoch: 028, Training: Loss: 5.1535, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 38.3380s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 29/3000\n",
      "Epoch: 029, Training: Loss: 5.1535, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 36.4517s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 30/3000\n",
      "Epoch: 030, Training: Loss: 5.1535, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 38.1515s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 31/3000\n",
      "Epoch: 031, Training: Loss: 5.1535, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 38.6502s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 32/3000\n",
      "Epoch: 032, Training: Loss: 5.1535, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 33.2929s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 33/3000\n",
      "Epoch: 033, Training: Loss: 5.1535, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 36.5296s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 34/3000\n",
      "Epoch: 034, Training: Loss: 5.1535, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 38.6874s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 35/3000\n",
      "Epoch: 035, Training: Loss: 5.1535, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1535, Accuracy: 0.5780%, Time: 21.4556s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 36/3000\n",
      "Epoch: 036, Training: Loss: 5.1534, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 31.1431s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 37/3000\n",
      "Epoch: 037, Training: Loss: 5.1534, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.3281s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 38/3000\n",
      "Epoch: 038, Training: Loss: 5.1534, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.4559s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 39/3000\n",
      "Epoch: 039, Training: Loss: 5.1534, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.4818s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 40/3000\n",
      "Epoch: 040, Training: Loss: 5.1534, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.6598s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 41/3000\n",
      "Epoch: 041, Training: Loss: 5.1534, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.4424s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 42/3000\n",
      "Epoch: 042, Training: Loss: 5.1534, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 28.7982s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 43/3000\n",
      "Epoch: 043, Training: Loss: 5.1534, Accuracy: 0.4817%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 29.2589s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 44/3000\n",
      "Epoch: 044, Training: Loss: 5.1534, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 36.4188s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 45/3000\n",
      "Epoch: 045, Training: Loss: 5.1534, Accuracy: 0.5780%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 36.6282s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/3000\n",
      "Epoch: 046, Training: Loss: 5.1534, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.9259s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 47/3000\n",
      "Epoch: 047, Training: Loss: 5.1534, Accuracy: 0.4817%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.4105s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 48/3000\n",
      "Epoch: 048, Training: Loss: 5.1534, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.5105s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 49/3000\n",
      "Epoch: 049, Training: Loss: 5.1534, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.6558s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 50/3000\n",
      "Epoch: 050, Training: Loss: 5.1534, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.5091s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 51/3000\n",
      "Epoch: 051, Training: Loss: 5.1534, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.6168s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 52/3000\n",
      "Epoch: 052, Training: Loss: 5.1534, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.6009s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 53/3000\n",
      "Epoch: 053, Training: Loss: 5.1534, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.5152s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 54/3000\n",
      "Epoch: 054, Training: Loss: 5.1534, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 36.6871s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 55/3000\n",
      "Epoch: 055, Training: Loss: 5.1534, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.3867s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 56/3000\n",
      "Epoch: 056, Training: Loss: 5.1534, Accuracy: 0.4817%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 36.8124s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 57/3000\n",
      "Epoch: 057, Training: Loss: 5.1534, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 26.9122s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 58/3000\n",
      "Epoch: 058, Training: Loss: 5.1534, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 31.1772s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 59/3000\n",
      "Epoch: 059, Training: Loss: 5.1534, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.4818s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 60/3000\n",
      "Epoch: 060, Training: Loss: 5.1534, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1534, Accuracy: 0.5780%, Time: 38.2412s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 61/3000\n",
      "Epoch: 061, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.7766s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 62/3000\n",
      "Epoch: 062, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.3431s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 63/3000\n",
      "Epoch: 063, Training: Loss: 5.1533, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 30.8197s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 64/3000\n",
      "Epoch: 064, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.6019s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 65/3000\n",
      "Epoch: 065, Training: Loss: 5.1533, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.3455s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 66/3000\n",
      "Epoch: 066, Training: Loss: 5.1533, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.2496s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 67/3000\n",
      "Epoch: 067, Training: Loss: 5.1533, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.5329s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 68/3000\n",
      "Epoch: 068, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.1835s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 69/3000\n",
      "Epoch: 069, Training: Loss: 5.1533, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.2560s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 70/3000\n",
      "Epoch: 070, Training: Loss: 5.1533, Accuracy: 0.0000%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.6593s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 71/3000\n",
      "Epoch: 071, Training: Loss: 5.1533, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.9858s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 72/3000\n",
      "Epoch: 072, Training: Loss: 5.1533, Accuracy: 0.0000%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.7351s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 73/3000\n",
      "Epoch: 073, Training: Loss: 5.1533, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 37.5431s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 74/3000\n",
      "Epoch: 074, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.3649s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 75/3000\n",
      "Epoch: 075, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.2527s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 76/3000\n",
      "Epoch: 076, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 37.9821s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 77/3000\n",
      "Epoch: 077, Training: Loss: 5.1533, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.2345s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 78/3000\n",
      "Epoch: 078, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.3580s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 79/3000\n",
      "Epoch: 079, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.9191s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 80/3000\n",
      "Epoch: 080, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.4389s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 81/3000\n",
      "Epoch: 081, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.5625s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 82/3000\n",
      "Epoch: 082, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.5492s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 83/3000\n",
      "Epoch: 083, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.3181s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 84/3000\n",
      "Epoch: 084, Training: Loss: 5.1533, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.2692s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 85/3000\n",
      "Epoch: 085, Training: Loss: 5.1533, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.4624s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 86/3000\n",
      "Epoch: 086, Training: Loss: 5.1533, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.1435s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 87/3000\n",
      "Epoch: 087, Training: Loss: 5.1533, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.2901s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 88/3000\n",
      "Epoch: 088, Training: Loss: 5.1533, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.2763s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 89/3000\n",
      "Epoch: 089, Training: Loss: 5.1533, Accuracy: 0.0000%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 34.4847s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 90/3000\n",
      "Epoch: 090, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.2674s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 91/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 091, Training: Loss: 5.1533, Accuracy: 0.5780%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.9120s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 92/3000\n",
      "Epoch: 092, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.4909s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 93/3000\n",
      "Epoch: 093, Training: Loss: 5.1533, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.4644s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 94/3000\n",
      "Epoch: 094, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.5537s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 95/3000\n",
      "Epoch: 095, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.2902s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 96/3000\n",
      "Epoch: 096, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.3271s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 97/3000\n",
      "Epoch: 097, Training: Loss: 5.1533, Accuracy: 0.3854%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.3884s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 98/3000\n",
      "Epoch: 098, Training: Loss: 5.1533, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.1329s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 99/3000\n",
      "Epoch: 099, Training: Loss: 5.1533, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.4494s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 100/3000\n",
      "Epoch: 100, Training: Loss: 5.1533, Accuracy: 0.0963%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.3043s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 101/3000\n",
      "Epoch: 101, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.7703s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 102/3000\n",
      "Epoch: 102, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.3809s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 103/3000\n",
      "Epoch: 103, Training: Loss: 5.1533, Accuracy: 0.1927%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 36.6334s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n",
      "Epoch: 104/3000\n",
      "Epoch: 104, Training: Loss: 5.1533, Accuracy: 0.2890%, \n",
      "\t\tValidation: Loss: 5.1533, Accuracy: 0.5780%, Time: 38.2184s\n",
      "Best Accuracy for validation : 0.0087 at epoch 003\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3000\n",
    "trained_model, history = train_and_valid(resnet50, loss_func, optimizer, num_epochs)\n",
    "torch.save(history, 'models/'+dataset+'_history.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = np.array(history)\n",
    "plt.plot(history[:, 0:2])\n",
    "plt.legend(['Tr Loss', 'Val Loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(dataset+'_loss_curve.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history[:, 2:4])\n",
    "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(dataset+'_accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "“transfer_learning_tutorial.ipynb”的副本",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
